\chapter{Analysis} \label{analysis}

This Chapter explores the insights gained through analysis of the results detailed in Chapter \ref{results} and Appendix \ref{appendixDetailedResults}.

The analysis follows the pattern of Chapter \ref{results} by analysing the system in terms of its three major functional areas in the following sections:

\begin{itemize}
	\item Length and Extremity Measurement
	\item 3D Modelling
	\item User Interface
\end{itemize} 

\section{Length and Extremity Measurement}
This section begins with overall insights gained about this functional area. Afterwards, further analysis is done of each of the major sub-functions:

\begin{itemize}
	\item Human Detection
	\item Extremity Detection
	\item Measurement Validation
\end{itemize}

\subsection{Overall}
The system performed mostly successfully in terms of the aims stipulated in Section \ref{methodologyAim}. 

Below is a summary of performance in comparison with the quantitative aims:

\begin{itemize}
	\item The average accuracy tolerance of the overall system was 23.15\% - (Aim: $<25\%$)
	\item The length accuracies achieved ranged from 3.12\% to 8.53\% - (Aim: $<20\%$)
	\item 75\% of the Views met the "View" aim (The "Left" View achieved the worst accuracy of 28.19\%) - (Aim: $<25\%$)
	\item 80\% of the limb measurements met the Limb aim (The Chest (38.77\%) and the Waist (34.26\%) performed the worst) - (Aim: $<25\%$)
	\item Clothing, on average, increased the inaccuracy of the system by 66.08\% - (Aim: $<30\%$)
	\item The average uncertainty of each limb measurement ranged from 1.44\% to 7.20\% - (Aim: $<10\%$)
\end{itemize}

Despite using a relatively small data set, the system was deemed to be effective for a variety of body types - The characteristics of Volunteers used for analysis included "Build", "Height" and "Clothing". (A summary of this can be seen in Table \ref{tab:overallAccuracy}). However, it was noticed that certain characteristics may have been responsible for the systems lack of performance in certain areas and will be explained in subsequent sections.

Additionally, the physical measurements taken for comparison had a certain amount of uncertainty as the apparatus available for measurement was analogue and not perfectly suited for the the experiment. Therefore, the results of the system could be slightly better or worse. However, this increased level of accuracy is not necessary for the purposes of a first attempt at the project to get an overall understanding of the effectiveness of this approach. Methods to evaluate the accuracy to a finer level of detail would be essential for a final implementable solution.

\subsection{Human Detection}
%This section analyses the effectiveness of the Kinect and its %capabilities for its intended use in the project scope. 

\subsubsection{Body Detection}
The first major aspect of the system is whether it could adequately detect a human body. As mention in Section \hl{(Insert Reference)}, this was achieved by using the Kinect's inbuilt skeleton tracking capability together with its BackgroundRemoval Class.

The visible effectiveness of this method manifested in the detection of the full human body of each volunteer, together with a rendering of their skeleton, that appeared in the User Interface. (Refer to Appendix \ref{appendixDetailedResults} for examples of images taken during final testing). 

\subsubsection{3D Measurement}
The next process in the detection process was to understand if the depth data collected by the Kinect was reliable for 3D measurement. This has been validated by previous projects \hl{(Insert Reference)}, but the measurement of key lengths in the body, performed during this project, also acted as an indirect "acid-test" validation. This is largely due to the fact that the points used to measure the lengths were well established "Joints" in the tracked "Skeleton", where each "Joint" had a clearly identifiable 3D location. Therefore, comparing the measurements obtained through calculation to actual measurements was able to give a rough indication of the accuracy of the Kinect's data. Since all the key lengths had an average accuracy of within 10\%, the data collected by the Kinect was deemed appropriate for not just human detection, but for measurement as well. 

\subsubsection{Kinect Failures}
Despite the suitability of Kinect demonstrated above, there were certain instances where its performance was inadequate and negatively impacted the overall performance of the system. These are explained in the following paragraphs. 

\paragraph{Range and Resolution}
The Kinect has a limited operating window and resolution for its depth data as mentioned in Section\hl{(Insert reference)}. This range is further limited in order to ensure the entire human body is detected. 

The depth resolution used for this project was 640 x 480, which was the maximum available by the Kinect. The Kinect also has a maximum working range of 2.5m (I.e. Any further diminishes the quality fo the depth data). It was determined that at a height of approximately 1m (101.5 cm), most volunteers had to stand further at 2m or further to be detected. This limited window together with the limited depth resolution, caused a physical limitation on the accuracy of the system and is another reason for the decreased performance. 

\paragraph{Detection}
It was observed that the Kinect's human detection and skeleton tracking was most effective when the volunteer was directly facing it. This is clear from the performance of the measurements in the "Front" view and the lack of miscellaneous errors such as missing measurements. This can be attributed to the fact that the Kinect performs the best when a person faces it head on (Parallel to the image plane). This is due to the Kinect being able to fully track the skeleton of the user. As a result, a more accurate and reliable skeletal coordinate system can be used, which in turn provide more accurate planes of measure. 

The Kinect's ability to detect volunteers facing $90^{\circ}$ (I.e. "Left" or "Right" view) from itself is limited and detecting volunteers facing $180^{\circ}$ (I.e. "Back" view) from itself is even worse. During testing, it was noted that measurements in the different views was only possible if the volunteer's skeleton was already tracked (I.e. facing the Kinect at some point). 

Additionally, the Kinect is not built to detect a person if he/she has his/her back to it. If the skeleton is tracked, due to the person facing it at some point, and they now have their back to the Kinect, the Kinect cannot differentiate this from the skeleton facing it directly. To compensate for this in the system, the left and right sides of the body were switched in the algorithm to simulate the turning of the body. However, it was noticed that the skeleton would not map to the body as well as if the person was facing it directly. Also, joints would often be "Inferred" or "Not Tracked". This is the reason for the Back View being prone to errors such as "Incorrect Pixel Removal" or "Missing Measurements" explained in Section \ref{empiricalObservations}. 

\paragraph{Inferred Joints}
As mentioned in \hl{(Insert Reference)}, when the Kinect is unable to track a "Joint" due to it being out of view, the Kinect will "infer" its position. These "Inferred Joints" are useful in understanding characteristics of the detected person such as their 3D orientation. However, they often have a great deal of uncertainty in the modelling of their exact position and thus, for a single position and orientation of a detected person, the position of the "Inferred Joint" could change drastically. This makes it undesirable for measurement purposes.

The view selection in User Interface is used to compensate for this as the algorithm neglects the body parts out of sight (For example, if the person has the left side of their body facing the camera, the skeleton on right side will not be rendered). The only issue with this is in determining the "Waist" measurement in either the "Left" or the "Right" View. Since only one hip is clearly detected by the "Kinect", the other one is often "Inferred". The "Waist" measurement is taken across both hips and due to the inaccuracy of the "Inferred Joint", the plane of measurement for the "Waist" is unpredictable. This is what causes the "Incorrect Waist Plane" error mentioned in Section \ref{empiricalObservations}. 

To compensate for this, the operator of the User Interface often would instruct the volunteer to slightly rotate their body for a more accurate "Waist" reading. However, this introduces other issues such as changing the axes of measurement for the limbs and occasionally causes "Overlap Errors" in the "Lower Leg" measurements. This is therefore not an effective empirical workaround of the problem. 

\paragraph{Jitter}
This refers to the phenomenon observed where the rendered skeleton of the tracked person "moves around" or "jitters" when there is live tracking. Even if a person is relatively still, the "Jittering" of the skeleton is still noticed. This is predominately due to the presence of noise in the measurement process of the person. This causes a slight variation in the skeleton of the tracked person at a given instant. Since the skeleton is used as the coordinate system for all measurements, this is not ideal as it introduces a level of uncertainty.  

Additionally, it was observed that "Inferred Joints" experience an even greater "Jitter". This makes them even more unreliable and further explains the occurrence of the "Incorrect Waist Plane" error. 

\paragraph{Skeleton Mapping}
It was occasionally noticed that the skeleton of detected human often did not map accurately to the colour image. This was caused due to issues mentioned above like "Jittering" and the Kinect's inability to detect a human facing away from it. 
The incorrect mapping causes both an inconsistency in the measurement planes and an error in a measurement due to the incorrect plane being used. 

Additionally, it was noticed that due to the limited resolution of the Kinect's depth data and the limited workable distance from the Kinect, the skeleton mapping of "Skinny" individuals lower Arms and legs was poor. As seen in Section \ref{empiricalObservations} under "Missing Measurements", Volunteer 4's "Lower Left Arm" and "Lower Right Arm" measurements were missing. Upon inspection of Figures \ref{fig:volunteer4Back} and \ref{fig:volunteer4Left}, it is clear that due to the individual's smaller frame and the uncertainty in the skeleton mapping, it is actually mapped to underneath the actual arm (Outside the boundaries of the lower arm). 

This meant that the skeleton was mapped to the "background removed" part of the image and caused the algorithm to believe the arm had no extremities. This in turn, caused the incorrect reading of "0cm". This is not a significant problem with larger framed individuals as the large surface area of their limbs ensures that even if their is uncertainty in the skeleton mapping, it is more likely to still map to within the boundaries of the limb. 


\subsection{Extremity Detection}
As seen from the overall performance summary above, the system performed relatively well in detecting extremities of the body. As seen in Section \hl{(Insert Reference)}, the detection of extremities combined the ability of the Kinect's internal BackgroundRemoval Class, together with an algorithm that also took depth data into account.  

However, there were certain cases mentioned in Chapter \ref{results}, where the extremity detection failed or was erroneous. The major contributing factors to this are explored in the following subsections:

\subsubsection{Clothing}
As mentioned in Section \hl{(Insert Reference)}, clothing worn by the volunteer was expected to have an effect on the system's performance. 

However, what was not expected was the dramatic impact it would have on the results. On average, clothing worsened the accuracy of the results by 66.08\%. This shows that the system is clearly not designed to be robust against clothing worn by the volunteers.

Fortunately, this can be compensated for by ensuring the person being measured wears either tight clothing or is wearing as little clothing as possible. However, in a fully implementable solution, more work should be done in including this compensation for clothing algorithmically. Possible methods are explained in Chapter \ref{recommendations}. 

\subsubsection{Padding}
This addition of pixels around the body (Introduced in Section \ref{empiricalObservations}), was responsible for increased inaccuracy in measurements of various limbs. 

In most cases, the "Padding" caused the measurements to be inflated. The part of the algorithm created to compensate for this, effectively detects stray pixels that form part of the background that are too far from the body. The reason why it was also not excluded by the algorithm is because these pixels have approximately the same depth from the camera as the body. As a result, the BackgroundRemoval Class includes them, and the algorithm cannot differentiate between them and the body. 

\subsubsection{Overlap}
The "Overlap" error was also a major contributor to inaccuracies. The system was unable to detect an overlap in the same way it could not detect extra padding - The overlap of two body parts meant that a continuous measurement line was created over both body parts as the expected removed background was not reached (Explained in section \ref{empiricalObservations}). 

Additionally, the depth analysis part of the algorithm could not differentiate between the body parts as their average depth is too close. There were no other means to differentiate edges and such, this error would occasionally occur.

To compensate for this, the person being measured can be instructed to hold a specific position that limits the presence of overlap errors. However, this has impacts on the usability of the system and is covered in Section \ref{UIAnalysis}. Also, this does not always work as is the case with the "Left" and "Right" views. Besides the "Waist Plane" error mentioned above, overlap errors were a major contributor to the inaccuracies of these views. 

\subsubsection{Kinect Accuracy}
The resolution and range limitation of the Kinect has an impact on the accuracy of extremity determination. (The person being detecting having to be a certain distance away from the sensor and the depth data not having a high enough resolution to provide very precise and accurate data). This manifests itself in two predominate manners:

\paragraph{Data Collection} 
The low resolution of the depth sensor means the data collected about the exact position of the person has a certain level of uncertainty. Additionally, for finer measurements such as the precise measurements of the extremities, the lack of precise positional data causes error propagation throughout the system.

\paragraph{Errors}
The low resolution is also a contributor for many of the errors mentioned in Section \ref{empiricalObservations}. For example, the low resolution means the system has to be less sensitive to depth data. This makes it more difficult to differentiate between body parts (Overlap) and the background (Padding). Additionally, the depth data is prone to noise and contributes to errors in skeleton mapping, background removal and the part of the algorithm that analyses depth data. 


\subsection{Measurement Validity}

\subsubsection{Uncertainty}
As seen above, the average uncertainty of the measurements of the all individual limbs was less than 10\%. In fact, even all the individual uncertainties measured in the different views were also less than 10\%. 

This means that the system is relatively precise and there is minimal variation between multiple readings of a person in the same position. (I.e. a measurement obtained is reliable). That being said, the system currently only takes one reading of a person in each respective view (4 readings in total). Instead, multiple readings could be taken in each view and then aggregated to provide an even more reliable results. This is explored in Chapter \ref{recommendations}. 

However, the uncertainty may be slightly worse than the values calculated, as the volunteer used to measure the uncertainty was instructed to hold specific positions by the operator. These positions were selected to removed errors such as "Overlap" or the "Incorrect Waist Plane" error. Therefore, without the intervention of the operator, these uncertainty values may be higher. To implement a multiple reading system mentioned in the paragraph above, more stringent error checking must first be employed algorithmically. 

\subsubsection{Error Checking} 
At present, the only method of error checking is the operator validating whether a measurement is accurate enough or not (This "manual feedback loop" is explained in Section \ref{measurementProcess}). 

The problem with this method is that it requires a lot of effort on the part of the operator together with specific knowledge of errors for which to look. Additionally, the operator may be able to pick up obvious errors such as large overlaps or a waist plane with significant deviation. However, due to the large amount of information, it would be easy to miss small errors such as small overlaps, slight deviations in the waist plane and/or missing limb measurements. 

For an implementable solution, the load on the operator should be reduced and more error checking and validation should be done algorithmically. This will move towards a more autonomous solution, with less reliance on the operator and improve the accuracy of readings. 

\section{3D Modelling}

\subsection{Overall}
An effective implementation of 3D circumference modelling from the extremities and lengths determined, was not successfully achieved. 

Below is a summary of the performance of the two models used in comparison with the quantitative aims:

\begin{itemize}
	\item The average accuracy tolerance of the ellipse model was 106.82\% - (Aim: $<30\%$)
	\item The average accuracy tolerance of the rectangle model was 35.80\% - (Aim: $<30\%$)
\end{itemize}

It is clear that neither of the models performed within the aim of 30\%. However, the rectangle model came very close with an average accuracy of 35.80\%. This result was not expected as it was originally theorized that the ellipse model would yield better results. 

It should also be noted however, that errors made during the extremity measurements, would propagate through the system and impact the circumference. Additionally, factors such as the presence of clothing would also greatly impact the result. Therefore, if these measurements were improved, this would also result in an improvement in the accuracy of the models.   

Further analysis of each individual model is presented below:  

\subsection{Ellipse Model}
The ellipse model performed much worse than expected. The accuracy values for the different limbs ranged from 60.06\% to 148.70\%. 

This wide spread of accuracies and large deviation from the actual circumference measurements indicates that the ellipse is not a suitable shape to model the 3D circumference of body parts in this application.

Closer inspection of the measurements of the volunteers obtained together with empirical observations revealed that human limbs are often more elongated and less ovular. 

Additionally, the ellipse perimeter is modelled using the length of its minor and major axes. The algorithm was built on the assumption that the $90^{\circ}$ rotation in between each measurement would adequately provide measurements for the two axes. However, further analysis of the system revealed that the measurements obtained often did not correspond to the major and minor axes. Instead, they would correspond to diameters or chords slightly off either axis, due to factors such as the slight rotation of the arm during measurement. Frequently, this error in modelling was exacerbated by the algorithm because the minor axis was often given a value that was too big. As a result, the shape being modelled was more along the lines of a circle with a diameter of the longest part of the limb. This is the reason for the large circumference values.  

\subsection{Rectangle Model}
The rectangle model performed much better than expected. The accuracy values for the different limbs ranged from 18.89\% to 49.28\%.

This spread of results and deviation from the actual circumference measurements was significantly better than the results of the ellipse method.

This model can better deal with the elongation of limbs. Additionally, the slight variations in orientation that greatly impacted the ellipse model, do not affect this model as much. This model evidently creates a much tighter circumference approximation than the ellipse method. 

This method, however, still does not meet the requirements of have an accuracy of less than 30\%. For an implementable solution, this accuracy would have to be further decreased to a value in the region of 5\%. Therefore, there is still much work to be done in improving the accuracy of the modelling. 

The positive takeaway is that this model can be used to create the maximum boundary or encapsulation of the circumference. With further data points or improved measurement techniques, this modelled can be adjusted down to more accurately fit the circumference (E.g. Add curvature to the corners etc.). 

\section{User Interface} \label{UIAnalysis}

\subsection{Autonomy}
As eluded to in previous sections, the system as it stands relies on the operator or user to a large extent. The system dependencies on the user are listed below:

\begin{itemize}
	\item User must select the appropriate view measurement
	\item User must execute the measurement process
	\item User must error check each "View" measurement
	\item User must instruct person being measured how to orientate for optimum results 
\end{itemize}

\paragraph{View Selection}
The selection of "Views" in the user interface is effective in that ensures only one view is chosen at a time. It also has a relevant status update when a new view is chosen. However, the reliance of the user to choose the correct "View" is large. This causes an area of operation that is prone to error as the user can often forget to choose a new view or the correct view. This should be made more autonomous with algorithms that automatically detect the correct view depending on the orientation of the body. If this is not implemented, at least more visible warnings should be shown to guide the user if he/she makes a mistake (E.g. Tries to take a new measurement when the orientation of the measured body has obviously changed).

\paragraph{Measurement Process}
The measurement process itself relies on the user significantly. All though all the background processing is handled and abstracted from the user, the user still needs to initiate the process, perform validation on the output measurements and advise the measured person how to adjust their body for better readings. This empirical correction and execution would require the use to be train and/or spend a great deal of time and effort during the measurement process. Additionally, it makes the system more prone to error as the user may miss small mistakes in the process. This is not ideal for the user or the person being measured and may cause frustration towards the system, resulting in a lack of adoption. The measurement process should be made far more autonomous before a solution is implementable. Suggestions for this are given in Chapter \ref{recommendations}.

\subsection{Aesthetics}
This is the first version of a basic working solution and as such, is missing a few key design elements. Besides the error checking procedures that should be included, mentioned in the above section, the interface itself would have to be redesigned to optimise user ease-of-use, comfort and effectiveness. This would be accomplished by making the interface more intuitive with more obvious controls and more messages. A few required improvements are listed below:

\begin{itemize}
	\item Improve the colour scheme of the interface to make the experience for the user more enjoyable
	\item Increase the size and/or improve the locations of buttons to make them more easily accessible
	\item Make the status bar more visible and/or use more pop-up windows
	\item Have different screens to guide the user through the process
	\item Make the data easily exportable (E.g. To a database or Excel spreadsheet)
\end{itemize} 
