\chapter{Solution Design}
This chapter details and explains various aspects of the solution design. It begins with a explanation of the envisioned implementation of the solution in the clothing industry ecosystem. This is followed by a detailed account of the design process used to create the solution and lastly, an extensive overview of the experimental process used to test the solution.

\section{Implementation Design}

\subsection{Overview}
The solution aims to form part of larger practical implementation that will be applicable and provide relief in all three clothing channels mentioned in Section \ref{clothingIndustryContext}. However, in order to understand the needs the implementation must address, an analysis of pain points of consumers and producers in each channel must be performed. Shown in Table \ref{tab:conProdPainPoints} is a summary of such an analysis.

\begin{table}[htbp]
	\centering
	\caption{Pain points of consumers and producers in each of the three channels}
	\begin{tabularx}{\textwidth}{|Y|Y|Y|}
		\toprule
		& 
		\textit{\textbf{Consumers}} & 
		\textit{\textbf{Producers}} \\
		\midrule
		\textit{\textbf{Retail}} & 
		\begin{itemize}
			\item Visiting stores is time consuming
			\item Trying clothes on is tedious
			\item The correct size is often not available 
		\end{itemize} & 
		\begin{itemize}
			\item Dressing rooms waste valuable space
			\item Trying on clothes pose a security risk and require resources to control
			\item Significant costs are incurred during exchanges 
		\end{itemize} \\
		\midrule
		\textit{\textbf{Online}} & 
		\begin{itemize}
			\item Difficult to choose the correct size
			\item Not sure how the item will look on body
			\item Frustrating to exchange if item is incorrect
		\end{itemize} & 
		\begin{itemize}
			\item Exchanges severely impact their profitability
			\item Experience lower sale volume due as they cannot provide a complete customer experience
		\end{itemize}\\
		\midrule
		\textit{\textbf{Tailoring}} & 
		\begin{itemize}
			\item Only available for specialised clothing
			\item The process is time consuming
			\item There is always delay between getting measured and picking up clothing
		\end{itemize} & 
		\begin{itemize}
			\item Time required to complete measurements limits productivity
			\item Measurements can only take place in person with a trained tailor
		\end{itemize} \\
		\bottomrule
	\end{tabularx}%
	\label{tab:conProdPainPoints}%
\end{table}%


The aim of the overall implementation is to alleviate stresses on both consumers and suppliers that are inherent to the status quo.  In order to achieve this, the implementation will consist of the following key components: 

\begin{itemize}
	\item A compact, expedient and easy to use system that accurately measures the body parameters of a customer and provide clothing suggestions
	\item A platform that retains this customer information and creates a digital profile accessible to the customer and shareable between retailers  
	\item An intuitive interface that allows the customer to seamlessly get advise on clothing at his/her retailers of choice	
\end{itemize} 

These key components were developed into a more detailed end-to-end journey of the implementation. This is given in the following section.

\subsection{End-to-End Implementation Journey}
A diagram illustrating the high-level functioning of the entire implementation is seen in Figure \ref{fig:endToEndImplementation}.

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{End_to_End_Implementation.png}
	}}
	\caption{An illustration of the End-to-End journey of the envisioned implementation}
	\label{fig:endToEndImplementation}
\end{figure}

The implementation can be broken down into three major subsystems that are mentioned and explained in the following subsections:

\subsubsection{Measurement System} \label{measureSystem}
This system's main purpose is to be able to determine the personalised body parameters of a customer and then generate a full 3D model of their body to provide useful information such as suggestions for clothing sizes. It will achieve this by using a Kinect, or another device with depth sensing capabilities. 

The vision is that the Kinect would be integrated into a specially designed room. The customer would need to step into this room and hold certain poses. The Kinect, together with a back-end processing unit, would then create a full 3D. The entire process from start to finish should be less than ten minutes. 

This is the most integral part of the implementation as it allows for the realisation of the other two subsystems mentioned below. The main focus of this project is creating a first attempt at this subsystem. As such, its design and functioning are covered in great detail in Section \hl{(Measurement Design)}. 

\subsubsection{Store Integration}
In order to facilitate the measuring process, a room, integrated with a Kinect, would need to be placed at a convenient location for customers. Two possibilities are explored here:

\paragraph{Traditional Retailers}
There is a significant incentive for these retailers to provide a space for this "virtual room". (Expanded upon in Section \hl{(Benefits)}) As such, given that this system aims to limit the need for physically trying on clothes, one of the spaces previously dedicated to a dressing room could be upgraded to this new virtual room. Minimal change to the infrastructure would be required and this also frees up more space as unused dressing rooms can be replaced. 

In this instance, consumers would be able to record their measurements when visiting the clothing store. The measurements would be recorded and they can continue their clothing shopping with a better understanding of sizes. Since the customer would already be shopping and the process only needs to occur once (Assuming no change to the customer's body), it seems likely that their would be buy-in into the system.

\paragraph{Partners}
If there is enough interest by various companies, a measurement booth can be built in a commonly used location (I.e. in a shopping mall). Any customer visiting this booth, would automatically have profiles at all the companies sharing the booth. This is the other alternative if a specific company does not want to dedicate their floor space for this solution, but rather outsource it. This would also be the most likely method in which an online store can partake to allow for digital profiles of their shoppers to be created.

\subsubsection{Cloud Management of Profile}
Once the measurements of a person are determined and a digital profile is created, that information can now be more easily transferred. Partnerships may be made between clothing companies, online companies and even perhaps tailors. They may agree to share this information for an agreed upon amount and allow the costumer to have clothing suggestions for all the stores they shop at. Alternatively, a single online platform may be created that stores all these profiles and if a clothing supplier partners up with it, it can then provide information to the customers regarding the supplier's specific line of clothing.

\subsubsection{Potential Benefits}
The effective and practical implementation of the above system has significant potential benefits for each of the stakeholders. Table \ref{tab:conProdBenefits} contains a summary of the potential benefits for consumers and producers in the different channels.

\begin{table}[htbp]
	\centering
	\caption{Potential benefits for consumers and producers in each of the three channels}
	\begin{tabularx}{\textwidth}{|Y|Y|Y|}
		\toprule
		& 
		\textit{\textbf{Consumers}} & 
		\textit{\textbf{Producers}} \\
		\midrule
		\textit{\textbf{Retail}} & 
		\begin{itemize}
			\item No longer need to waste time and effort trying on clothes
			\item Significantly reduces the shopping time required
			\item Knowing exact sizes allows for calling ahead to check for availability
		\end{itemize} & 
		\begin{itemize}
			\item More floor space to use more productively
			\item Alleviates the security risk of trying on clothes
			\item Will likely cause a reduction in costs due to exchanges
		\end{itemize} \\
		\midrule
		\textit{\textbf{Online}} & 
		\begin{itemize}
			\item Knowing exact sizes reduces uncertainty of online shopping
			\item Potential for clothe viewing using augmented reality
			\item Reduces the need to exchange
		\end{itemize} & 
		\begin{itemize}
			\item Reduces the costs associated with returns
			\item Can expect an uptick in sales
			\item No longer need to have an overly lenient returns policy
		\end{itemize}\\
		\midrule
		\textit{\textbf{Tailoring}} & 
		\begin{itemize}
			\item Process is quick and only needs to happen once
			\item Measurements can be sent ahead of time to reduce delay
			\item No need to visit tailor before collection
		\end{itemize} & 
		\begin{itemize}
			\item Reduce time taken for readings will improve productivity
			\item No longer limited by number of skilled tailors
			\item Might make mass production of custom clothing possible
		\end{itemize} \\
		\bottomrule
	\end{tabularx}%
	\label{tab:conProdBenefits}%
\end{table}%

\section{Component Level Design}
This section details the design process used to create the measurement system mentioned in Section \ref{measureSystem}. It first begins with the selection process used to choose both the hardware and software of the system. It then proceeds into the design of the algorithm, which forms the largest part of the design process.

\subsection{Component Selection}

\subsubsection{Hardware}

\paragraph{Depth Sensor}
When this project was first proposed, no hardware system was specified for use, However, it was indicated that a depth sensor should be the first technology explored to achieve this. Depth sensor technology has extensively been involved in projects performing analysis on human bodies. As such, this suggestion was used and a depth sensor was the hardware device chosen for the project. 

The next step was to determine the particular depth sensor used. Initially, due to ease of availability, sensors such as the Intel RealSense, Asus XtionPRO Live and the Kinect for Xbox 360 were considered. However, it was swiftly decided that the Kinect be the sensor of choice. The reasons for this are given below:

\begin{itemize}
	\item The Kinect has in built skeleton tracking functionality
	\item Microsoft has released an SDK (Software Development Kit) that allows for effective interfacing with the Kinect 
	\item Many previous research papers have utilised the Kinect and thus the support for it is extensive
	\item This project is for research purposes and there are no license conflicts with using the Kinect in this capacity
\end{itemize}

\paragraph{Kinect Choice}
The next significant decision, however, was the version of Kinect used for the project. The first part of the process was the decision between the Kinect for Xbox 360 (Version 1 - v1) or the Kinect for Xbox One (Version 2 -v2). 

The Kinect v2 uses ToF (Time-of-Flight) technology that has been shown to improve its accuracy. It also does not falter as significantly as the Kinect v1 in extreme constitutions such as darkness or direct sunlight. It also has a better working range as the accuracy of the Kinect v1's depth sensor degrades exponentially as the distance away from the sensor increases whereas the Kinect v2 stays almost constant over the same range. \cite{kinectComp2011} This can be seen in Figure \ref{fig:kinectV1V2Depth}. 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{kinectV1vsV2Depth.png}
	}}
	\caption{A graph showing the comparison of the accuracy and standard deviation of the Kinect v1 and Kinect v2 as distance from the sensor increases \cite{kinectComp2011}}
	\label{fig:kinectV1V2Depth}
\end{figure}

However, despite these performance advantages of the Kinect v2, the Kinect v1 was chosen for this project for the following reasons:

\begin{itemize}
	\item The Kinect v1 was already available for use and the Kinect v2 was not
	\item The tolerance advantage of the Kinect v2 to extreme condition is mitigated by:
	\begin{itemize}
		\item The Kinect will perform in normal conditions - I.e. It will be indoors, in a well lit room with no direct light shining on the Kinect (Mentioned more in detail in \hl{(Experiment Design Ref)}).
		\item The Kinect v1 and v2 have very similar performance in normal conditions \cite{kinectComp2011}
	\end{itemize}
	\item Skeletal tracking only works effectively up to a distance of 3.5m (Section \hl{(Skel Tracking Ref)}) and the difference in accuracy of the depth sensors only becomes significant after 3m as seen in Figure \ref{fig:kinectV1V2Depth}. Working within the 3m range makes the accuracy difference negligible.
\end{itemize}

Lastly, the Kinect for Xbox 360 was chosen instead of the Kinect for Windows for the following reasons:

\begin{itemize}
	\item The Kinect for Xbox 360 with a USB adapter was already available
	\item These two Kinects are almost functionally identical, except for near range depth mode being unavailable in the Kinect for Xbox \hl{(Kinect Near Range Mode)}
	\item Near Range mode is not utilised in this project and thus, this lack of functionality is no essential.
\end{itemize}

\subsubsection{Software}
The software used to design this solution was largely dictated by the choice of the Kinect as the underlying hardware. 

In order to maximise the functionality of the Kinect, the Kinect for Windows SDK was utilised. This SDK provides an API (Application Programming Interface) for the Kinect in both C\# and C++ programming languages. 

C\# was chosen as the language in which to build the solution as at this stage of the project, finite control over aspects of the Kinect offered by the C++ is not necessary. 

Also provided with the SDK, is Microsoft Toolkit for the Kinect. This toolkit contains further functionality over and above those provided by the SDK. Included with the toolkit are full coded examples of different basic applications using the Kinect SDK and toolkit to demonstrate how to use them. Each of these examples come with their own documentation and are in the form of Visual Studio Projects.

Visual Studios is Microsoft's official IDE (Integrated Development Environment). It supports development in a variety of languages including C\# and C++. Due to the SDK reliance on Visual Studios, its wide functionality and extensive online support, it was chosen as the IDE for this project. 

\hl{(Include NUI Info and Samples used + Documentation)}

\subsection{Algorithm Design}
As mentioned above, the main part of this solutions design was in the design of the algorithms required to make the measurement subsystem a reality. This section details the design process followed and begins with an overview of the created system and how it functions. Proceeding that is an explanation of the system's architecture and finally, extensive details about the functional blocks that form the measurement subsystem. 

\subsubsection{Overview}
Seen in Figure \ref{fig:overallAlgorithm}, is a depiction of the real-time functioning of the overall measurement system. (I.e. This illustrates the process required from converting a detected human to a 3D Model of themselves). 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{OverallAlgorithm.png}
	}}
	\caption{An illustration of the overall functioning of the measurement subsystem created.}
	\label{fig:overallAlgorithm}
\end{figure}

The overall functioning is know illustrated with a walk-through of the system:

\paragraph{Step 1: } A customer (person being measured), steps in front of the Kinect sensor at a specified distance and faces it directly. (Operation conditions explained more in Section \hl{(Experiment Design)}) At the same time, an operator controls the UI (User Interface) on the host computer. The operator specifies that the user is facing the Kinect directly and records the readings of the customer. An image of the customer, with a rendered skeleton (Green Lines) and measurement planes (Red Lines), together with their 3D readings appear on the UI. These readings correspond to the 3D distance of the extremities of their respective limb (I.e. The 3D distance between the start and end point of the red lines). An example of this is seen in Figure \ref{fig:designVol2Front}. 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{Volunteer2_Front_Blurred.png}
	}}
	\caption{An example of the UI when the front reading of a customer is taken}
	\label{fig:designVol2Front}
\end{figure}

\paragraph{Step 2: } The customer rotates $90^{\circ}$ clockwise and exposes the left side of the their body. The operator specifies that the customer is displaying the left side of their body and records the readings. An updated image and set of readings populate the UI. An example of this is seen in Figure \ref{fig:designVol2Left}. 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{Volunteer2_Left.png}
	}}
	\caption{An example of the UI when the left reading of a customer is taken}
	\label{fig:designVol2Left}
\end{figure}

\paragraph{Step 3: } The customer rotates another $90^{\circ}$ clockwise and is now facing $180^{\circ}$ away from the Kinect. The operator specifies that the customer is displaying their back and records the readings. An updated image and set of readings populate the UI. An example of this is seen in Figure \ref{fig:designVol2Back}. 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{Volunteer2_Back.png}
	}}
	\caption{An example of the UI when the back reading of a customer is taken}
	\label{fig:designVol2Back}
\end{figure}	

\paragraph{Step 4: } The customer rotates a final $90^{\circ}$ clockwise and is now displaying the right side of their body to the Kinect. The operator specifies that the customer is displaying their right side and records the readings. An updated image and set of readings populate the UI. An example of this is seen in Figure \ref{fig:designVol2Right}. 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{Volunteer2_Right_Blurred.png}
	}}
	\caption{An example of the UI when the right reading of a customer is taken}
	\label{fig:designVol2Right}
\end{figure}

\paragraph{Step 5: } All the necessary readings have been taken and the customer is free to move. A results button now becomes available for the operator. When pressed, a pop-up window is displayed with the 3D circumferences and lengths of certain parts of the customer's body. An example of this is seen in Figure \ref{fig:designVol2Front}. At this point, another program would run that maps the 3D circumference values to clothing sizes that can help advise the customers shopping choices. (This application is part of the envisioned solution but was not implemented in this project). 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{Volunteer2_Circumference.png}
	}}
	\caption{An example of the UI when the results button is pressed and final pop-up window is shown.}
	\label{fig:designVol2Circum}
\end{figure}

Now that an overall feel for the system has been gained, a more detailed explanation of the architecture and functional blocks will be given in following sections. 

\subsubsection{Architecture}
The overall program consists of three classes and a main WPF (Windows Presentation Foundation) form or window. The window is the UI of the system and facilitates the interaction of the operator with the program. The three classes created and used are SkeletonLib, Measure and Circumference3D. The overall interaction between the classes and the main window is depicted in Figure \ref{fig:algorithmArchitecture}. 

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{algorithmArchitecture.png}
	}}
	\caption{An illustration of the programs architecture and their interconnections}
	\label{fig:algorithmArchitecture}
\end{figure}

\subsubsection{Functional Blocks}
This section goes into detail about the functional blocks of the measurement subsystem or program. The system can be broken into 3 major functional blocks that will be explained in the following paragraphs:

\paragraph{Measurement} The primary functional block is responsible for obtaining readings for the extremities of the measured person's body. A summary of the process is provided below:

\begin{enumerate}
	\item Use BackgroundRemoval API to receive background removed image.
	\item Create SkeletonLib Object and send it Skeleton and background removed image.
	\item Render skeleton and joints using API.
	\item Create perpendicular measurement planes on the arms, legs and spine and plane across hips for waist.
	\item Starting at the bone, iterate through the colour pixels on the measurement planes until a start and end point is detected.
	\item Use the Measure class to obtain the 3D distances using the start and end points.
	\item Store the value for each measurement.
\end{enumerate}

For certain aspects of the above process, further explanations are given below:

\subparagraph{Measurement Planes}
The readings taken in this process correspond to the Lower and Upper Left and Right Arms, Lower and Upper Left and Right Legs, Chest and Waist. Their positions can be seen in Figure: \ref{fig:measurementPlanes}.

\begin{figure}[ht]
	\centering
	{%
		\setlength{\fboxsep}{0pt}%
		\setlength{\fboxrule}{0.5pt}%
		\fbox{
			\includegraphics[width=0.7\textwidth]{measurementPlanes.png}
	}}
	\caption{An illustration of the programs architecture and their interconnections}
	\label{fig:measurementPlanes}
\end{figure}

For the arms, legs and chest measurements, all starting points were defined as the midpoint of the bone on which they were situation. In order to create these planes, the negative reciprocal of the gradient of the bone on which they resided and the starting point (midpoint) was used to create a straight line function perpendicular to the bone. Navigating along this plane entailed moving in either the positive or negative x-direction returning a new y-value. The colour pixel at that given coordinate would then be returned an analysed.

\subparagraph{Determining Start and End Points}
An extremity was defined as the first pixel detected along the measurement plane that was trannsparent (Pixels removed from the background had their 4th bit set to 0 therefore signalling that they were transparent and removed)



1) Windows examples used - Background Removal, Colour Stream and Skeleton Tracking - NB - Why BackgroundRemoval instead of own method
3D Points - No calibration

2) Run through of algorithm
- Background Removed frame
- Send image to separate class for processing
- Create array with background removed pixels
- Draw skeleton on image
- Create axes for measurement - Perpendicular or straight depending on particular measurement

\section{Experimental Design}
- Constraints - Men, distance from Kinect, height of Kinect, Number of views, 3D Modelling, control distance - box of 0.5m
- UI to run simulated dressing room
- Volunteer to pose as instructed by person controlling UI
- Take measurement of front
- Take left
- Take back
- Take right 
- At each point, take actual readings with uncertainty
- Note: Did not use correction in \cite{nonContact2017}
- For one volunteer, take 5 readings in relatively the same pose - Determine uncertainty 