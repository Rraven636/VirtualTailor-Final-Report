\chapter{Analysis} \label{analysis}

This Chapter explores the insights gained through analysis of the results detailed in Chapter \ref{results} and Appendix \ref{appendixDetailedResults}.

The analysis follows the pattern of Chapter \ref{results} by analysing the system in terms of its three major functional areas in the following sections:

\begin{itemize}
	\item Length and Extremity Measurement
	\item 3D Modelling
	\item User Interface
\end{itemize} 

\section{Length and Extremity Measurement}
This section begins with overall insights gained about this functional area. Afterwards, further analysis is done of each of the major sub-functions:

\begin{itemize}
	\item Human Detection
	\item Extremity Detection
	\item Measurement Validation
\end{itemize}

\subsection{Overall}
The system performed mostly successfully in terms of the aims stipulated in Section \ref{methodologyAim}. 

Below is a summary of performance in comparison with the quantitative aims:

\begin{itemize}
	\item The average accuracy tolerance of the overall system was 23.15\% - (Aim: $<25\%$)
	\item The length accuracies achieved ranged from 3.12\% to 8.53\% - (Aim: $<20\%$)
	\item 75\% of the Views met the "View" aim (The "Left" View achieved the worst accuracy of 28.19\%) - (Aim: $<25\%$)
	\item 80\% of the limb measurements met the Limb aim (The Chest (38.77\%) and the Waist (34.26\%) performed the worst) - (Aim: $<25\%$)
	\item Clothing, on average, increased the inaccuracy of the system by 66.08\% - (Aim: $<30\%$)
	\item The average uncertainty of each limb measurement ranged from 1.44\% to 7.20\% - (Aim: $<10\%$)
\end{itemize}

Despite using a relatively small data set, the system was deemed to be effective for a variety of body types - The characteristics of Volunteers used for analysis included "Build", "Height" and "Clothing". (A summary of this can be seen in Table \ref{tab:overallAccuracy}). However, it was noticed that certain characteristics may have been responsible for the systems lack of performance in certain areas and will be explained in subsequent sections.

Additionally, the physical measurements taken for comparison had a certain amount of uncertainty as the apparatus available for measurement was analogue and not perfectly suited for the the experiment. Therefore, the results of the system could be slightly better or worse. However, this increased level of accuracy is not necessary for the purposes of a first attempt at the project to get an overall understanding of the effectiveness of this approach. Methods to evaluate the accuracy to a finer level of detail would be essential for a final implementable solution.

\subsection{Human Detection}
%This section analyses the effectiveness of the Kinect and its %capabilities for its intended use in the project scope. 

\subsubsection{Body Detection}
The first major aspect of the system is whether it could adequately detect a human body. As mention in Section \hl{(Insert Reference)}, this was achieved by using the Kinect's inbuilt skeleton tracking capability together with its BackgroundRemoval Class.

The visible effectiveness of this method manifested in the detection of the full human body of each volunteer, together with a rendering of their skeleton, that appeared in the User Interface. (Refer to Appendix \ref{appendixDetailedResults} for examples of images taken during final testing). 

\subsubsection{3D Measurement}
The next process in the detection process was to understand if the depth data collected by the Kinect was reliable for 3D measurement. This has been validated by previous projects \hl{(Insert Reference)}, but the measurement of key lengths in the body, performed during this project, also acted as an indirect "acid-test" validation. This is largely due to the fact that the points used to measure the lengths were well established "Joints" in the tracked "Skeleton", where each "Joint" had a clearly identifiable 3D location. Therefore, comparing the measurements obtained through calculation to actual measurements was able to give a rough indication of the accuracy of the Kinect's data. Since all the key lengths had an average accuracy of within 10\%, the data collected by the Kinect was deemed appropriate for not just human detection, but for measurement as well. 

\subsubsection{Kinect Failures}
Despite the suitability of Kinect demonstrated above, there were certain instances where its performance was inadequate and negatively impacted the overall performance of the system. These are explained in the following paragraphs. 

\paragraph{Range and Resolution}
The Kinect has a limited operating window and resolution for its depth data as mentioned in Section\hl{(Insert reference)}. This range is further limited in order to ensure the entire human body is detected. 

The depth resolution used for this project was 640 x 480, which was the maximum available by the Kinect. The Kinect also has a maximum working range of 2.5m (I.e. Any further diminishes the quality fo the depth data). It was determined that at a height of approximately 1m (101.5 cm), most volunteers had to stand further at 2m or further to be detected. This limited window together with the limited depth resolution, caused a physical limitation on the accuracy of the system and is another reason for the decreased performance. 

\paragraph{Detection}
It was observed that the Kinect's human detection and skeleton tracking was most effective when the volunteer was directly facing it. This is clear from the performance of the measurements in the "Front" view and the lack of miscellaneous errors such as missing measurements. This can be attributed to the fact that the Kinect performs the best when a person faces it head on (Parallel to the image plane). This is due to the Kinect being able to fully track the skeleton of the user. As a result, a more accurate and reliable skeletal coordinate system can be used, which in turn provide more accurate planes of measure. 

The Kinect's ability to detect volunteers facing $90^{\circ}$ (I.e. "Left" or "Right" view) from itself is limited and detecting volunteers facing $180^{\circ}$ (I.e. "Back" view) from itself is even worse. During testing, it was noted that measurements in the different views was only possible if the volunteer's skeleton was already tracked (I.e. facing the Kinect at some point). 

Additionally, the Kinect is not built to detect a person if he/she has his/her back to it. If the skeleton is tracked, due to the person facing it at some point, and they now have their back to the Kinect, the Kinect cannot differentiate this from the skeleton facing it directly. To compensate for this in the system, the left and right sides of the body were switched in the algorithm to simulate the turning of the body. However, it was noticed that the skeleton would not map to the body as well as if the person was facing it directly. Also, joints would often be "Inferred" or "Not Tracked". This is the reason for the Back View being prone to errors such as "Incorrect Pixel Removal" or "Missing Measurements" explained in Section \ref{empiricalObservations}. 

\paragraph{Inferred Joints}
As mentioned in \hl{(Insert Reference)}, when the Kinect is unable to track a "Joint" due to it being out of view, the Kinect will "infer" its position. These "Inferred Joints" are useful in understanding characteristics of the detected person such as their 3D orientation. However, they often have a great deal of uncertainty in the modelling of their exact position and thus, for a single position and orientation of a detected person, the position of the "Inferred Joint" could change drastically. This makes it undesirable for measurement purposes.

The view selection in User Interface is used to compensate for this as the algorithm neglects the body parts out of sight (For example, if the person has the left side of their body facing the camera, the skeleton on right side will not be rendered). The only issue with this is in determining the "Waist" measurement in either the "Left" or the "Right" View. Since only one hip is clearly detected by the "Kinect", the other one is often "Inferred". The "Waist" measurement is taken across both hips and due to the inaccuracy of the "Inferred Joint", the plane of measurement for the "Waist" is unpredictable. This is what causes the "Incorrect Waist Plane" error mentioned in Section \ref{empiricalObservations}. 

To compensate for this, the operator of the User Interface often would instruct the volunteer to slightly rotate their body for a more accurate "Waist" reading. However, this introduces other issues such as changing the axes of measurement for the limbs and occasionally causes "Overlap Errors" in the "Lower Leg" measurements. This is therefore not an effective empirical workaround of the problem. 

\paragraph{Jitter}
This refers to the phenomenon observed where the rendered skeleton of the tracked person "moves around" or "jitters" when there is live tracking. Even if a person is relatively still, the "Jittering" of the skeleton is still noticed. This is predominately due to the presence of noise in the measurement process of the person. This causes a slight variation in the skeleton of the tracked person at a given instant. Since the skeleton is used as the coordinate system for all measurements, this is not ideal as it introduces a level of uncertainty.  

Additionally, it was observed that "Inferred Joints" experience an even greater "Jitter". This makes them even more unreliable and further explains the occurrence of the "Incorrect Waist Plane" error. 

\paragraph{Skeleton Mapping}
It was occasionally noticed that the skeleton of detected human often did not map accurately to the colour image. This was caused due to issues mentioned above like "Jittering" and the Kinect's inability to detect a human facing away from it. 
The incorrect mapping causes both an inconsistency in the measurement planes and an error in a measurement due to the incorrect plane being used. 

Additionally, it was noticed that due to the limited resolution of the Kinect's depth data and the limited workable distance from the Kinect, the skeleton mapping of "Skinny" individuals lower Arms and legs was poor. As seen in Section \ref{empiricalObservations} under "Missing Measurements", Volunteer 4's "Lower Left Arm" and "Lower Right Arm" measurements were missing. Upon inspection of Figures \ref{fig:volunteer4Back} and \ref{fig:volunteer4Left}, it is clear that due to the individual's smaller frame and the uncertainty in the skeleton mapping, it is actually mapped to underneath the actual arm (Outside the boundaries of the lower arm). 

This meant that the skeleton was mapped to the "background removed" part of the image and caused the algorithm to believe the arm had no extremities. This in turn, caused the incorrect reading of "0cm". This is not a significant problem with larger framed individuals as the large surface area of their limbs ensures that even if their is uncertainty in the skeleton mapping, it is more likely to still map to within the boundaries of the limb. 


\subsection{Extremity Detection}
As seen from the overall performance summary above, the system performed relatively well in detecting extremities of the body. As seen in Section \hl{(Insert Reference)}, the detection of extremities combined the ability of the Kinect's internal BackgroundRemoval Class, together with an algorithm that also took depth data into account.  

However, there were certain cases mentioned in Chapter \ref{results}, where the extremity detection failed or was erroneous. The major contributing factors to this are explored in the following subsections:

\subsubsection{Clothing}
As mentioned in Section \hl{(Insert Reference)}, clothing worn by the volunteer was expected to have an effect on the system's performance. 

However, what was not expected was the dramatic impact it would have on the results. On average, clothing worsened the accuracy of the results by 66.08\%. This shows that the system is clearly not designed to be robust against clothing worn by the volunteers.

Fortunately, this can be compensated for by ensuring the person being measured wears either tight clothing or is wearing as little clothing as possible. However, in a fully implementable solution, more work should be done in including this compensation for clothing algorithmically. Possible methods are explained in Section \hl{(Insert Reference)}. 

\subsubsection{Padding}
This addition of pixels around the body (Introduced in Section \ref{empiricalObservations}), was responsible for increased inaccuracy in measurements of various limbs. 

In most cases, the "Padding" caused the measurements to be inflated. The part of the algorithm created to compensate for this, effectively detects stray pixels that form part of the background that are too far from the body. The reason why it was also not excluded by the algorithm is because these pixels have approximately the same depth from the camera as the body. As a result, the BackgroundRemoval Class includes them, and the algorithm cannot differentiate between them and the body. 

\subsubsection{Overlap}
The 

\subsubsection{Kinect Accuracy}


Padding\\
Clothing\\
Overlap - Orientation or position\\
Resolution\\
Distance\\

\subsection{Measurement Validity}
Uncertainty\\
Stats\\
Waist Plane\\

\section{3D Modelling}

\section{User Interface}

\iffalse

Mention data set?\\

The observed factors that had the greatest contribution to inaccuracy are listed below in order of impact:

\begin{enumerate}
	\item The system not being able to accurately determine the extremities of the body.
	\item The inconsistency of the plane being used to take the measurement.
	\item The error or "jitter" of the tracked skeleton.
\end{enumerate}



The results obtained in Table \ref{tab:viewResults}, together with the detailed results of each volunteer available in Appendix \ref{appendixDetailedResults} have yielded insights for each of the views. They are discussed in the subsequent subsections. 

\subsection{Front Performance}

The "Front" view performed the best overall with an average accuracy of 20.67\%. This can be attributed to the fact that the Kinect performs the best when a person faces it head on (Parallel to the image plane). This is due to the Kinect being able to fully track the skeleton of the user. As a result, a more accurate and reliable skeletal coordinate system can be used, which in turn provide more accurate planes of measure. 

All joints and skeleton tracked 

\subsection{Left Performance}

\subsection{Back Performance}

The "Back" view performed better than expected despite the average error of 23.11\%

\subsection{Right Performance}

Front was the most accurate

Misc\\
Missing - Height, Skinny, Back, Skeleton Mapping
8) Empirical Insights - Trying to determine a correct measurement,  length of people, skinny person, skeleton not perfectly fitting, background edges not perfect \\

5) Uncertainty model\\

\fi